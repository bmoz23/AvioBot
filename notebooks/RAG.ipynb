{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "958aecb8-7073-40c7-a305-caba2d5a2874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv(\"req.env\"), override=True)\n",
    "\n",
    "#os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d82798f-a08d-4999-9511-8ef837144d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3beac2a5-0d9a-4589-b2cb-01e37a64f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7130fe9f-a858-4446-84cc-672ac11306c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "    \n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        try:\n",
    "            loader = PyPDFLoader(file_path=file)\n",
    "            data = loader.load()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading PDF file: {e}\")\n",
    "            return None\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        try:\n",
    "            loader = Docx2txtLoader(file)\n",
    "            data = loader.load()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading DOCX file: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print('Document format is not supported')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ad3231f-9a9e-4cee-a103-3da392980369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks=text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b809443f-00be-4e70-985b-a031be10c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def print_embedding_cost(texts):\n",
    "    enc= tiktoken.encoding_for_model('text_embedding-ada-002')\n",
    "    total_tokens=sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000 *0.0004:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfe055-be71-49c3-8f59-d991cef77e1e",
   "metadata": {},
   "source": [
    "# Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e1bacad-6a62-44ea-8d59-196ccd421e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import PodSpec\n",
    "    pc= pinecone.Pinecone()\n",
    "    embeddings=OpenAIEmbeddings(model='text_embedding-3-small', dimension=1536)\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings...', end='')\n",
    "        vector_store= Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings...', end='')\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=PodSpec(environment = 'gcp-starter')\n",
    "            \n",
    "        )\n",
    "        vector_store=Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d0d226ee-d9c1-48a5-aab5-6a1c9c7ce851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings1(index_name, chunks):\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain.embeddings import OpenAIEmbeddings  # Doğru yolu kontrol edin\n",
    "    from pinecone import PodSpec\n",
    "\n",
    "    # Pinecone API anahtarınızı eklemeniz gerekebilir # Pinecone API anahtarınızı buraya ekleyin\n",
    "    pc= pinecone.Pinecone()\n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')  # OpenAI modelini doğru şekilde belirtin\n",
    "\n",
    "    pc = pinecone.Pinecone()\n",
    "    \n",
    "    if index_name in pc.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings...', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings...', end='')\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=PodSpec(environment = 'gcp-starter')\n",
    "        )\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "509a5bbb-4c12-4b7e-bcd2-365c2d4c8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc =pinecone.Pinecone()\n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        print('Deleting all indexes...')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854e0ec-6f06-4002-b229-9f474c99f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65b034-747b-43cf-9e42-2cd43c6491d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b57a62-73d7-4636-b46f-49515aef5dea",
   "metadata": {},
   "source": [
    "# Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "961d7e10-6669-4250-96f7-5c13ba9b648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    if vector_store is None:\n",
    "        raise ValueError(\"Vector store is None, cannot proceed with the retrieval.\")\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "    \n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    # k equals 3 means that it will return the three most similar chunks to the user's query.\n",
    "    \n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)\n",
    "\n",
    "    answer = chain.run(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90322b80-6fc8-4492-8e99-f4e91d6b415f",
   "metadata": {},
   "source": [
    "## Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bbba8391-6075-4b7f-a6ba-cd3d9771e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading den.pdf\n",
      "we have 1 pages\n"
     ]
    }
   ],
   "source": [
    "data = load_document('den.pdf')\n",
    "\n",
    "print(f'we have {len(data)} pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a95ad5b-c9fc-4997-9407-2ed427e480ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "testing. She used unit test, selenium test, white box test, and black box test. The \n",
      "company name is BİMSER. She has new internship about Python backend development.\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07388cde-f8bf-48d0-99a5-20890ec4f9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09272652-25a5-4615-8ec8-063f91b5a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askdocument and embeddings...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name= 'askdocument'\n",
    "vector_store =insert_or_fetch_embeddings1(index_name, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e5e3ebc5-e694-45c8-8272-0ce67a10797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic of İlayda Öcal's presentation is cyber security in avionic systems.\n"
     ]
    }
   ],
   "source": [
    "q = 'What is the topic of presentation of ilayda öcal'\n",
    "answer= ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f00ffa16-9bff-4495-9c8c-1ef499216a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your secondary field is applied data science.\n"
     ]
    }
   ],
   "source": [
    "q2= 'what is my secondary field'\n",
    "answer2= ask_and_get_answer(vector_store, q2)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7fbd1e43-eb4a-4c74-9d66-c45ce00b655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The people mentioned in the context are:\n",
      "1. Rufat Naghiyev\n",
      "2. Ayman Hamdan\n"
     ]
    }
   ],
   "source": [
    "q3='list all people that are mentioned in the context'\n",
    "answer3=ask_and_get_answer(vector_store,q3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9f6e20b-27e3-4a96-85ca-20d832415313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document seems to be about the user's internship experiences and projects related to artificial intelligence, cyber security in avionic systems, machine learning concepts, and various technologies such as LLMs, NLP, LangChain, and vector databases. It appears that the document may also include a presentation prepared for the company administrator.\n"
     ]
    }
   ],
   "source": [
    "q4='what is the whole document about?'\n",
    "answer4=ask_and_get_answer(vector_store,q4)\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ac624-2ad5-4708-b8b7-53ecf0281622",
   "metadata": {},
   "source": [
    "# Using ChromaDB as Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "570cbca2-9499-478d-8e64-ca8f02c15087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'hnswlib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for chroma-hnswlib\n",
      "ERROR: Could not build wheels for chroma-hnswlib, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -q chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189aac2-5d75-4109-ac7b-fc072f6aa5a8",
   "metadata": {},
   "source": [
    "#  Adding Memory (Chat History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6bee0551-71e1-4d76-8752-d3d947cfa07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=0)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':5})\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "crc= ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff', # all of the text from documents\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54119557-8648-489c-ab59-36692109e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(q, chain):\n",
    "    chain.invoke({'question':q})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745298f-1732-406e-a1cd-bd85bf2e932d",
   "metadata": {},
   "source": [
    "# Using a Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "951cfd3f-9000-4faf-8369-7f036aa9f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=0)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':5})\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "system_template = '''\n",
    "Use The following pieces of context to answer the user's question.\n",
    "---------------------\n",
    "Context: {context}\n",
    "'''\n",
    "\n",
    "user_template = '''\n",
    "Question: {question}\n",
    "Chat History: {chat_history}\n",
    "'''\n",
    "\n",
    "messages=[\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template)\n",
    "]\n",
    "\n",
    "qa_prompt= ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "crc= ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type='stuff', # all of the text from documents\n",
    "    combine_docs_chain_kwargs={'prompt':qa_prompt},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778c248-f369-4c83-b6ad-9f61286ddc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05873c1-106e-49d7-ad55-9a076ba57076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
