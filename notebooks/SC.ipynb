{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cee24c65-9821-417e-b353-1e5603cd30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import fitz\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3eb99e-8405-411d-b00f-95cff848eb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv(\"req.env\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e8bc0f-3172-4556-861e-b3ed68a479b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc= Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d659a7ce-1f24-4b70-9b3c-47d4cb66b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is created successfully\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name='sc2'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536, # default dimension for text embedding, one of the recommended OpenAI's embedding models.\n",
    "    metric='cosine', # algorithm to calculate distance between vectors.\n",
    "    spec= ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    print('Index is created successfully')\n",
    "\n",
    "else:\n",
    "    print(f'Index {index_name} already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a515e1a-25df-4c10-8771-e6a058e5f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import fitz\n",
    "\n",
    "with fitz.open(\"sc2.pdf\") as pdf:\n",
    "    # Extract text from each page\n",
    "    churchill = \"\"\n",
    "    for page in pdf:\n",
    "        churchill += page.get_text()\n",
    "    \n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "684d6726-c653-4271-a0fa-3d7e8e6dbd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now we have 2 chunk\n"
     ]
    }
   ],
   "source": [
    "print(f'now we have {len(chunks)} chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265d011e-6bef-43d2-b88f-2d0d815ee3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM and retriever\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69009406-f7e5-44e8-92de-c4867e799d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it appears that all the systems listed are ready, such as the helipad, battery voltage, EGI, radar, launcher, radome, FLIR, and DVR. Therefore, it could be inferred that the flight is indeed ready.\n"
     ]
    }
   ],
   "source": [
    "# Query the chain\n",
    "query = 'the flight is ready??'\n",
    "answer = chain.run(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53ed9f-31ee-4fe1-bb2f-ac0de97e65ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709f34f-7eef-4b6f-ac65-2488e46e4e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94528d8-f3e3-4695-b395-2d3489d16b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e63a851-7013-48cb-a29f-3f56e0b6330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a checker for copilot. If all attributes are READY, you give the response like everything is ready. But if one of the attributes is NOT READY, you give the response like flight cannot be started.\"),\n",
    "    HumanMessage(content=\"The flight is ready to fly?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334b03fe-a267-47c9-8cd6-78bfd74fbce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv(\"req.env\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f12f25d-7314-4e48-879d-4603cc2b7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc= Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b907e16-4d45-402a-9438-a8f9701f3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is created successfully\n"
     ]
    }
   ],
   "source": [
    "index_name='sce2'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536, # default dimension for text embedding, one of the recommended OpenAI's embedding models.\n",
    "    metric='cosine', # algorithm to calculate distance between vectors.\n",
    "    spec= ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    print('Index is created successfully')\n",
    "\n",
    "else:\n",
    "    print(f'Index {index_name} already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d9ebbb5-1909-4bc9-86b9-741d3a98f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d19aaa4-973c-4c4a-8e90-eced38cbf3f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "from_documents is not a top-level attribute of the Pinecone class provided by pinecone's official python package developed at https://github.com/pinecone-io/pinecone-python-client. You may have a name collision with an export from another dependency in your project that wraps Pinecone functionality and exports a similarly named class. Please refer to the following knowledge base article for more information: https://docs.pinecone.io/troubleshooting/pinecone-attribute-errors-with-langchain\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mPinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pinecone\\control\\pinecone.py:679\u001b[0m, in \u001b[0;36mPinecone.from_documents\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_build_langchain_attribute_error_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: from_documents is not a top-level attribute of the Pinecone class provided by pinecone's official python package developed at https://github.com/pinecone-io/pinecone-python-client. You may have a name collision with an export from another dependency in your project that wraps Pinecone functionality and exports a similarly named class. Please refer to the following knowledge base article for more information: https://docs.pinecone.io/troubleshooting/pinecone-attribute-errors-with-langchain\n"
     ]
    }
   ],
   "source": [
    "vector_store = Pinecone.from_documents(chunks, embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b62055-6d16-49f4-90e7-bbbf08def76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6139e-8ad1-4788-98a2-c37952b10360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4da687-8f8c-40d2-9985-6d155677782e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33964abe-7072-4779-bdf3-9bd37f727da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e3947-eb8e-4fd4-93e5-b960d6468cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output= llm.invoke(messages)\n",
    "print(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
